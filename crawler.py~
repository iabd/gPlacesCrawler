class crawler:
    cities=[]
    places=[]
    communes=[]
    
    def __init__(self, types, inputString, radius, key):
        self.types=types
        self.inputString=inputString
        self.radius=radius
        self.key=key

    def getCommunes(self):
        ssl._create_default_https_context=ssl._create_unverified_context
        page=urllib.request.urlopen('https://en.wikipedia.org/wiki/Alphabetical_list_of_comunes_of_Italy') 
        soup=BeautifulSoup(page)                                                        
        communesData=[]                                                                 
        for li_tag in soup.find_all('div', {'class':'div-col columns column-width'}):
            for list_tag in li_tag.find_all('li'):
                commune = list_tag.find('a').text
                communesData.append(commune)

        print('Fetched the list of communes! trying to get coordinates..')
        cords=[]
        for commune in communesData:
            url = ('https://maps.googleapis.com/maps/api/geocode/json?address=%s&region=%s&key=%s') % (commune, country, key)
            response = urllib.request.urlopen(url).read()
            jsonResponse = json.loads(response.decode('utf-8'))
            c = pd.DataFrame(jsonResponse['results'])
            cord = str(c.geometry[0]['location']['lat']) + ','+str(c.geometry[0]['location']['lng'])
            cords.append(cord)

        self.communes=pd.DataFrame({'commune':communesData, 'coordinates':cords})
        return cords
    

    def getLocations(self):
        ssl._create_default_https_context = ssl._create_unverified_context
        page=urllib.request.urlopen('https://en.wikipedia.org/wiki/List_of_cities_in_Italy').read()
        soup = BeautifulSoup(page)
        citiesData = []
        table = soup.find('table', attrs={'class':'wikitable sortable'})
        table_body = table.find('tbody')
        rows = table_body.find_all('tr')
        for row in rows:
            cols = row.find_all('td')
            cols = [ele.text.strip() for ele in cols]
            citiesData.append([ele for ele in cols if ele])
        cityData = pd.DataFrame(data = citiesData)
        listCities = cityData[cityData.columns[1:2]]
        listCities = listCities.drop(0, axis=0)
        listCities = listCities[1]
        print('Fetched the cities! Trying to get coordinates..')
        gn = geocoders.GeoNames(username='abdw')
        cords = []
        cord = 'NA'
        for cities in listCities:
            try:
 #               print('Getting coordinates for {} out of {} cities..'.format (listCities.index[cities], len(listCities)), end='\r')
                city = gn.geocode(cities)
                cord = str(city.latitude) + ',' + str(city.longitude)
            except Exception as e:
                print(e)
                break
            cords.append(cord)

        self.cities = pd.DataFrame({'city': listCities,'coordinates': cords,})
        #print(self.cities)
        return cords

    def fetchPlaces(self, location):
        import urllib, json
        import ssl
        import urllib
        from bs4 import BeautifulSoup
        import pandas as pd
        from geopy import geocoders
        import time
        ssl._create_default_https_context = ssl._create_unverified_context
        url = ('https://maps.googleapis.com/maps/api/place/nearbysearch/json'
                   '?location=%s'
                   '&radius=%s'
                   '&type=%s'
                   '&keyword=%s&key=%s') % (location,self.radius,self.types, self.inputString, self.key)
        response = urllib.request.urlopen(url).read()
        jsonResponse = json.loads(response.decode('utf-8'))
        x = pd.DataFrame(jsonResponse['results'])
        if 'next_page_token' in jsonResponse:
            tempVar=jsonResponse['next_page_token']
            url=('https://maps.googleapis.com/maps/api/place/nearbysearch/json'
               '?location=%s'
               '&radius=%s'
               '&type=%s'
               '&keyword=%s&key=%s&pagetoken=%s') % (location, self.radius, self.types,self.inputString, self.key, tempVar)
            time.sleep(2)
            response = urllib.request.urlopen(url).read()
            jsonResponse = json.loads(response.decode('utf-8'))
       #     print(jsonResponse)
            y=pd.DataFrame(jsonResponse['results'])
       #     print(len(y))
       #     print('length',len(x), '  ', len(y))
            z=pd.concat([x, y], ignore_index=True)
       #     x=x.append(y)
            self.places=z
            return z

        return x

    
        
        
